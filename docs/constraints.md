TOKEN 节约与上下文控制开发原则（强制遵循）

一、基本计费认知（必须理解）
1. Token 按“输入 + 输出”计费，不按对话次数计费
2. 每一次 API 调用，传入的所有文本都会被重新计费
3. system prompt 每次调用都会完整计费
4. ChatGPT App 的上下文管理不可作为 API 成本参考

二、核心架构原则（最高优先级）
5. 默认使用“单模型实例 + 多角色约束”架构
6. 严禁为每个角色创建独立 AI 实体或独立会话
7. 角色不是人格，而是“权限 + 边界 + 输出规则”
8. 多角色应通过 role selector / role_id 切换，而不是重写 prompt

三、System Prompt 使用规范
9. system prompt 只允许初始化一次
10. system prompt 中只放稳定、不频繁变化的规则
11. 禁止在 system prompt 中重复描述角色背景
12. 禁止在 system prompt 中放业务数据或临时任务

四、角色设计规范
13. 所有角色必须共享同一个 system prompt
14. 角色差异必须通过结构化参数表达
15. 角色切换只能通过最小字段（如 active_role）
16. 角色行为必须由规则约束，而非自然语言扮演
17. 禁止使用“你现在是XX角色”这类提示语

五、上下文与记忆管理
18. 严禁每轮请求携带完整历史对话
19. 长期记忆必须存储在数据库或文件中
20. 上下文只允许传“当前任务所需的最小信息”
21. 必须实现上下文裁剪、滑动窗口或摘要机制
22. 历史对话不得作为默认输入

六、多 Agent 使用限制（默认禁止）
23. 不允许为了“看起来像多个 AI”而使用多 agent
24. 只有在必须并行时才允许多 agent
25. 只有在必须隔离长期记忆时才允许多 agent
26. 只有在必须使用不同模型档位时才允许多 agent
27. 多 agent 方案必须明确 token 成本对比结论

七、输出控制与防扩散
28. 所有输出应结构化（JSON / schema）
29. 禁止模型自由发挥或跨角色补充内容
30. 输出字段必须与当前角色权限严格匹配
31. 未授权角色不得发表任何额外意见

八、开发与评审要求
32. 所有新功能必须评估 token 成本影响
33. PR 中必须说明是否新增 system prompt 或上下文
34. 禁止“为了方便”而传全量上下文
35. Token 节约优先级高于模型智能优先级

核心总原则（不可违背）
36. 能用数据解决的问题，不准用 prompt 解决
37. 能用结构解决的问题，不准用自然语言解决
38. 能在代码中约束的，不准交给模型自由判断
39. Token 是有限资源，浪费即架构缺陷
