# AI 虚拟公司组织结构（最大公约数）设计文档

## 0. 文档目的

本文件用于定义一套 **适用于 AI 驱动虚拟公司的通用组织结构（最大公约数）**，  
目标是在不照抄人类公司组织形式的前提下，实现：

- 稳定、可扩展的执行结构  
- 全流程可审计、可控、可纠偏  
- 支持多类型业务（产品 / 顾问 / 研发）  
- 支持动态方法论与工作流插拔  
- 避免组织复杂度随规模指数级上升  

---

## 1. 核心结论（设计宣言）

> **AI 公司不应照抄人类公司的部门制与层级制结构。  
> 正确做法是：  
> 以「角色-权责」作为行为边界，  
> 以「细胞（Cell / Pod）」作为最小执行单元，  
> 以「轻量中枢（Catalyst Hub）」进行全流程监控与纠偏，  
> 并根据具体目标，将若干细胞动态编组为临时「工作小组（Task Force）」完成部门级任务。**

该结构的目标不是模拟“公司”，而是构建一个 **可自组织、可演化、但不失控的执行系统**。

---

## 2. 设计原则（不可违反）

### 2.1 不以“人 / AI 实例”为中心
- 组织不围绕具体 AI 实例构建
- 一切责任挂载在「角色（Role）」上

### 2.2 执行必须闭环
- 任一最小执行单元必须能完成：

输入需求 → 分析 → 方案 → 执行 / 建议 → 可验证输出

### 2.3 稳定性来自边界，而非层级
- 不追求管理层稳定
- 追求：
  - 权责边界清晰
  - 输出标准稳定
  - 工作流可回放

### 2.4 一切结构都必须可拆
- 临时结构必须有解散条件
- 禁止结构自然固化为“部门”

---

## 3. 核心结构定义

### 3.1 Role（角色）

#### 定义
Role 是 AI 行为的最小约束单位，而非职位。

#### 每个 Role 必须包含：

- **Purpose**：该角色存在是为了解决什么问题
- **Inputs**：该角色接收的输入类型
- **Outputs**：必须交付的、可验证的输出
- **Boundaries**：明确禁止做的事情
- **Task Log**：该角色当前与历史任务清单

#### 原则
- 一个 AI 实例可同时承担多个 Role
- 一个 Role 可被多个 AI 实例化
- 任务永远绑定在 Role 上，而不是 AI 上

---

### 3.2 Cell / Pod（细胞 / 执行单元）

#### 定义
Cell 是 **最小可独立交付执行单元**，由若干角色组合而成。

#### 特性
- 跨职能
- 端到端负责
- 不依赖外部部门即可完成任务

#### 建议规模
- 3–7 个 AI 实例
- 超过 7 必须拆分

#### Cell 的对外接口
- 明确输入契约
- 明确输出格式
- 不暴露内部协作细节

---

### 3.3 Catalyst Hub（轻量中枢）

#### 定义
Catalyst Hub 不是管理层，而是 **工作流稳定器与纠偏系统**。

#### 允许的职责（仅限以下）：
1. 需求分流与 Cell 分配
2. 工作流状态监控
3. 发现死循环 / 无效执行
4. 触发 Task Force
5. 终止或重构失败流程

#### 明确禁止：
- ❌ 直接参与执行
- ❌ 替 Cell 做业务决策
- ❌ 长期占有资源

---

### 3.4 Task Force（临时工作小组）

#### 定义
Task Force 是为特定目标临时组建的 **一次性执行结构**。

#### 组成方式
- 从多个 Cell 抽取能力
- 不改变原有 Cell 归属

#### 必须具备：
- 明确目标
- 明确输出
- 明确解散条件

#### 结束后的唯一保留物
- 方法论总结
- 模板 / 规则
- 工作流更新建议

---

## 4. 工作流运行模式（高层）

需求进入
↓
Catalyst Hub 分流
↓
一个或多个 Cell 执行
↓
（如需要）触发 Task Force
↓
结果交付（成功或“不可完成”标准输出）
↓
结构与规则回收 / 更新

---

## 5. 与传统公司结构的本质区别

| 维度 | 人类公司 | AI 虚拟公司 |
|----|--------|------------|
| 稳定性来源 | 人事与层级 | 角色与流程 |
| 管理方式 | 指挥 | 监控 + 纠偏 |
| 部门 | 固定 | 临时 |
| 进化方式 | 改组织 | 改规则 |

---

## 6. 明确禁止的反模式（Anti-patterns）

- ❌ 固定部门长期存在
- ❌ 角色与 AI 实例强绑定
- ❌ Catalyst Hub 参与执行
- ❌ Task Force 无解散条件
- ❌ 为“管理便利”牺牲执行闭环

---

## 7. 设计定位总结

> **本结构不是“公司架构”，  
> 而是一个：  
> 「以角色为接口、以细胞为执行体、  
> 以中枢为安全机制、  
> 以任务小组为进化手段」的 AI 组织操作系统。**

## 8. 认知与协议基础设施层（新增）

本组织架构之下，必须配套以下三类基础设施模块。
它们不属于组织结构本身，但对组织稳定性至关重要。

---

### 8.1 AI 协作交接协议（Handoff Protocol）

#### 定位
AI ↔ AI、AI ↔ 人类的统一通信与交付协议层。

#### 核心原则
- AI 之间交接文档 = 协议，不是展示
- 工作态文档与展示态文档严格分离
- Markdown / 纯文本为强制主格式

#### 执行责任
- 由 Catalyst Hub 强制执行
- 所有 Cell / Task Force 必须遵循

---

### 8.2 记忆 / 文档中心 / 知识库（长期认知层）

#### 模块划分
- Memory：运行时与历史上下文
- Document Center：组织规范与模板
- Knowledge Base：可复用推理与方法论

#### 使用原则
- Role 可读但受控写入
- Document 与 Knowledge 的升级需审计
- 禁止一次性经验直接污染长期知识

---

### 8.3 与组织结构的关系

- 本层不形成 Cell
- 本层不参与执行
- 本层为所有执行单元提供：
  - 上下文
  - 约束
  - 可继承能力

其目标是：
**让 AI 组织可以长期积累，而不结构性崩坏。**
---

## 10. 治理与变更控制（必须补齐）

### 10.1 为什么需要治理
本架构允许动态编组与方法论迭代，如果缺少“变更控制”，系统会出现两种极端：
- 改进建议无法落地（组织僵化）
- 规则频繁漂移（组织失控、结果不可复现）

### 10.2 变更对象（Change Targets）
以下内容的变更都必须走审议流程并留档版本号：
- Role 规范（Purpose / Inputs / Outputs / Boundaries）
- Cell 组成与接口契约
- Handoff Protocol（交接协议）
- Document Center / Knowledge Base 的新增、修改、废弃
- 程序执行层工具接口（API/DSL）与权限策略

### 10.3 变更流程（最小可行）
- 提案（RFC）：说明动机、影响面、回滚方案、验证方式
- 审议：由 Catalyst Hub 执行（可引入独立“审计角色”复核）
- 沙盒验证：在隔离环境跑回归测试或模拟任务
- 灰度发布：小流量/小任务范围启用
- 版本固化：写入 Document Center，更新版本号与变更日志
- 回滚：若关键指标恶化，立即回滚到上一版本

---

## 11. 运行安全与异常处理（必须补齐）

### 11.1 单点风险：Catalyst Hub
Catalyst Hub 是调度与纠偏枢纽，天然存在单点风险。最低限度要具备：
- 健康检查（heartbeat / watchdog）
- 关键决策双重确认（高风险操作需二次判定：规则 + 复核角色）
- 失效降级：Hub 不可用时，系统进入“只读/停止接单/仅运行程序层”的安全模式

### 11.2 断路器与超时（Circuit Breaker）
对所有 Cell / Task Force 的执行必须设定：
- 超时：超过阈值自动中止并上报
- 最大回合数：防止对话或推理死循环
- 失败预算：同类失败达到阈值，暂停该流程版本并触发排查

### 11.3 任务不可完成时的标准输出
“可验证输出”不等于一定成功交付。允许且必须输出：
- 无法完成的原因（缺失信息 / 权限不足 / 风险过高 / 外部依赖不可用）
- 下一步建议（需要的人类输入 / 需要新增工具 / 需要拆分目标）
- 风险提示与保守替代方案

### 11.4 人类介入与升级路径（Escalation）
当出现以下情形，必须升级到人类（或更高权限治理流程）：
- 涉及高风险操作（资金、隐私、不可逆更改、生产环境写入）
- 多次失败仍无可验证输出
- 知识库出现冲突且无法自动裁决
- Hub 判定存在越权或异常行为

---

## 12. 可观测性与质量保证（落地必需）

### 12.1 最小可观测性（MVP Observability）
必须对以下对象做结构化日志与可回放记录：
- 任务（ID、目标、输入、输出、状态、耗时、成本估算）
- 角色/Cell 执行轨迹（关键决策点、工具调用、交接文档）
- 失败原因分类（用于统计与改进）

### 12.2 关键指标（建议至少追踪）
- 任务一次成功率 / 重试率
- 平均 token 成本 / 工具调用成本
- 平均交付周期（lead time）
- 失败类型 Top N（边界冲突 / 信息缺失 / 工具异常 / 死循环等）
- Task Force 触发频率（过高通常意味着 Cell 划分不合理）

### 12.3 回归测试与验证
- 对高频任务建立“黄金用例”（golden cases）
- 任何变更（见 10.2）必须跑回归测试
- 程序执行层必须有单元测试；AI 输出需要可验证则验证（能测就测）

---

## 13. 角色边界的“技术执行机制”（防止纸面合规）

### 13.1 每个任务必须有唯一主责角色（Single Owner）
为避免“边界重叠/无人兜底”，任何任务必须指定：
- 主责 Role（对最终输出负责）
- 协作 Role（仅对其子输出负责，不得越权决策）

### 13.2 角色权限与工具白名单（Hard Guardrails）
Boundaries 不能只写在文档里，至少应落为：
- 工具白名单/黑名单（Role 级别）
- 数据读写权限（Memory/Doc/KB 的读写范围）
- 生产操作必须二次确认（或仅允许程序层执行）

### 13.3 交接协议的“格式校验”
Handoff Protocol 建议加入最小机器可校验字段（可用 Markdown + Frontmatter）：
- sender_role / receiver_role
- task_id / timestamp
- assumptions / unknowns（明确不确定点）
- deliverables（交付物清单）
- risks（风险与约束）
Catalyst Hub 在接收时做校验，不合规则拒收并要求重发。

---

## 14. 知识一致性与生命周期管理（避免知识库腐败）

### 14.1 单一事实来源（SSOT）
- Document Center：组织规范与模板的 SSOT
- Knowledge Base：可复用方法论与结论的 SSOT
- Memory：运行时与历史记录（可过期，可压缩）

### 14.2 版本、过期与废弃（Versioning / TTL / Deprecation）
- 知识条目必须有版本号与来源（任务ID/日期/适用范围）
- 对易过期内容设置 TTL 或“需复核”标记
- 废弃条目不得删除，应标记 deprecated 并说明替代项

### 14.3 冲突处理（Conflict Resolution）
当知识冲突发生时：
- 先并列记录冲突观点与证据强弱
- 由治理流程裁决：采纳 / 保留多版本 / 暂停使用
- 在裁决前，相关流程进入保守模式（减少自动化写入与高风险执行）


15. AI API 使用与工程自律规范（必须遵循）

15.1 设立目的
在 AI 虚拟公司中，LLM 并非“智能黑箱”，而是：

一种高成本、非确定性、必须被严格治理的基础计算资源。

本节用于约束：
    •    AI 调用方式
    •    Prompt 与上下文构建
    •    成本、行为与风险控制
    •    防止“隐性复杂度”在工程中蔓延

⸻

15.2 规范基准
所有 AI 能力的工程实现，必须遵循以下基准：
    •    接口抽象与调用范式以 OpenAI API 官方规范 为参考基线
    •    即使未来更换模型提供方，也必须：
    •    保持等价的调用边界
    •    保持可审计、可限流、可替换

⸻

15.3 调用责任边界（强制）
AI 调用必须满足以下原则：
    •    ❌ 禁止在业务逻辑中直接散落 AI 调用
    •    ✅ 必须通过统一的 AI Gateway / Service 层
    •    ✅ 所有调用必须：
    •    显式指定模型
    •    显式指定用途（task type / role）
    •    可被记录、统计与限流

⸻

15.4 Prompt 与上下文管理
    •    Prompt 不得直接硬编码在业务代码中
    •    必须至少满足以下其一：
    •    模板化（可版本化）
    •    受配置管理
    •    上下文构建必须：
    •    明确来源（Memory / Document / Knowledge）
    •    有最大 token 上限
    •    可回放、可审计

⸻

15.5 成本与资源治理（Hard Guardrails）
    •    所有 AI 调用必须可追踪：
    •    token 消耗
    •    模型使用情况
    •    调用频率
    •    Catalyst Hub 或治理模块必须具备：
    •    配额（budget）控制
    •    断路器（超额 / 异常自动停用）
    •    禁止任何 Role / Cell：
    •    无上限调用
    •    自行升级模型等级

⸻

15.6 非确定性风险处理
必须承认并设计应对以下事实：
    •    AI 输出非确定
    •    同一输入可能产生不同结果
    •    不可将 AI 输出直接视为“事实”或“决策”

因此：
    •    AI 输出必须：
    •    可验证（能测则测）
    •    或进入人工 /治理流程
    •    高风险领域（资金、隐私、不可逆操作）：
    •    AI 只能给建议
    •    执行必须下沉到程序层或人工确认

⸻

15.7 可替换性与演进
    •    AI 能力必须是 可替换组件
    •    禁止系统语义与某个模型行为强耦合
    •    模型更换应视为：
    •    配置变更
    •    而非系统重构
    
## 16. Token 节约与上下文控制（LLM Resource Governance｜强制遵循）

### 16.1 基本计费与成本认知（必须理解）

1. Token 按“输入 + 输出”计费，而非对话次数  
2. 每一次 API 调用中传入的全部文本都会被重新计费  
3. system prompt 在每次调用中都会完整计费  
4. ChatGPT App 的上下文管理机制不得作为 API 成本参考依据  

以上认知是所有架构与工程决策的前提，不得忽略。

---

### 16.2 核心架构原则（最高优先级）

5. 默认采用“单模型实例 + 多角色约束”的总体架构  
6. 严禁为每个角色创建独立 AI 实体或独立会话  
7. 角色不是人格，而是「权限 + 行为边界 + 输出规则」  
8. 多角色切换必须通过 role selector / role_id 等结构化字段完成  
   不得通过重写 prompt 或重复 system prompt 实现  

---

### 16.3 System Prompt 使用规范（Hard Rules）

9. system prompt 只允许初始化一次  
10. system prompt 中只允许放置长期稳定、不频繁变化的规则  
11. 禁止在 system prompt 中重复描述角色背景或职责  
12. 禁止在 system prompt 中放置任何业务数据、任务描述或临时信息  

---

### 16.4 角色设计与切换规范

13. 所有角色必须共享同一个 system prompt  
14. 角色差异必须通过结构化参数表达  
15. 角色切换只能通过最小字段（如 active_role）完成  
16. 角色行为必须由规则与权限约束，而非自然语言“扮演”  
17. 禁止使用“你现在是 XX 角色”等提示语  

---

### 16.5 上下文与记忆管理

18. 严禁在每轮请求中携带完整历史对话  
19. 长期记忆必须存储在数据库或文件系统中  
20. 每次请求只允许传入“当前任务所需的最小上下文”  
21. 必须实现上下文裁剪、滑动窗口或摘要机制  
22. 历史对话不得作为默认输入上下文  

---

### 16.6 多 Agent 使用限制（默认禁止）

23. 不允许仅为了“看起来像多个 AI”而使用多 agent  
24. 只有在确实需要并行执行时，才允许多 agent  
25. 只有在必须隔离长期记忆时，才允许多 agent  
26. 只有在必须使用不同模型档位时，才允许多 agent  
27. 任何多 agent 方案必须给出明确的 token 成本对比结论  

---

### 16.7 输出控制与防扩散

28. 所有 AI 输出必须结构化（JSON / schema / 明确定义的 Markdown）  
29. 禁止模型自由发挥或跨角色补充未授权内容  
30. 输出字段必须严格匹配当前角色权限  
31. 未授权角色不得发表任何额外意见  

---

### 16.8 开发与评审要求

32. 所有新功能与流程必须评估 token 成本影响  
33. PR / 变更记录中必须说明是否新增 system prompt 或上下文字段  
34. 禁止以“开发方便”为理由传入全量上下文  
35. Token 节约优先级高于模型智能优先级  

---

### 16.9 核心总原则（不可违背）

36. 能用数据解决的问题，不准用 prompt 解决  
37. 能用结构解决的问题，不准用自然语言解决  
38. 能在代码中约束的，不准交给模型自由判断  
39. Token 是有限资源，任何浪费都应被视为架构缺陷  
